# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

# Data Loading
"""

# Download the data stored in a zipped numpy array from one of these two locations
# The uncommented one is likely to be faster. If you're running all your experiments
# on a machine at home rather than using colab, then make sure you save it 
# rather than repeatedly downloading it.
#!wget "https://sussex.box.com/shared/static/2nansy5fdps2dcycsqb7r06cddbbkskd.npz" -O training_images.npz
!wget "http://users.sussex.ac.uk/~is321/training_images.npz" -O training_images.npz
# The test images (without points)
!wget "http://users.sussex.ac.uk/~is321/test_images.npz" -O test_images.npz
# The example images are here
!wget "http://users.sussex.ac.uk/~is321/examples.npz" -O examples.npz
import numpy as np

# Load the data using np.load
data = np.load('training_images.npz', allow_pickle=True)

# Extract the images
images = data['images']
# and the data points
pts = data['points']

"""# Data Visualisation
Here's an example of how to display the images and their points
"""

print(images.shape, pts.shape)
def visualise_pts(img, pts):
  import matplotlib.pyplot as plt
  plt.imshow(img)
  plt.plot(pts[:, 0], pts[:, 1], '+r')
  plt.show()

for i in range(3):
  idx = np.random.randint(0, images.shape[0])
  visualise_pts(images[idx, ...], pts[idx, ...])

"""# Calculating Prediction Error and exporting results"""

def euclid_dist(pred_pts, gt_pts):
  """
  Calculate the euclidean distance between pairs of points
  :param pred_pts: The predicted points
  :param gt_pts: The ground truth points
  :return: An array of shape (no_points,) containing the distance of each predicted point from the ground truth
  """
  import numpy as np
  pred_pts = np.reshape(pred_pts, (-1, 2))
  gt_pts = np.reshape(gt_pts, (-1, 2))
  return np.sqrt(np.sum(np.square(pred_pts - gt_pts), axis=-1))

def save_as_csv(points, location = '.'):
  """
  Save the points out as a .csv file
  :param points: numpy array of shape (no_image, no_points, 2) to be saved
  :param location: Directory to save results.csv in. Default to current working directory
  """
  np.savetxt(location + '/results.csv', np.reshape(points, (points.shape[0], -1)), delimiter=',')

#save_as_csv(test_points_2)

#files.download("results.csv")

"""# Basic Regression Pipeline
Take a look at the FML lab on [linear regression](https://colab.research.google.com/drive/1P3gvarGJmrqatZ9ielZnT8_5yRoTHJ-b) to see a simple method for predicting real valued numbers.
"""

# Copy image arrays and points
train_imgs = np.copy(images)
train_pts = np.copy(pts)
# Look at the dimensions of each
print("Training images:",train_imgs.shape)
print("Training points:",train_pts.shape)

# turn images to grayscale
import cv2
import numpy as np
import matplotlib.pyplot as plt
G_TRAIN = []
for i in range(0,train_imgs.shape[0]):
  G_TRAIN.append(cv2.cvtColor(train_imgs[i],cv2.COLOR_BGR2GRAY))
G_TRAIN = np.array(G_TRAIN)
G_TRAIN.shape

plt.imshow(G_TRAIN[1])
plt.plot(train_pts[1][:,0],train_pts[1][:,1],'+r')
plt.show()

# rescale the images to 76x76
G_TRAIN_2 = []
for i in range(0,G_TRAIN.shape[0]):
  G_TRAIN_2.append(cv2.resize(G_TRAIN[i],(76,76)))
G_TRAIN_2 = np.array(G_TRAIN_2)
G_TRAIN_2.shape

# need to scale the points too since images are 76x76 now
G_PTS_2 = []
for i in range(0,train_pts.shape[0]):
  G_PTS_2.append(train_pts[i]*[76/250,76/250])
G_PTS_2 = np.array(G_PTS_2)
G_PTS_2.shape

plt.imshow(G_TRAIN_2[0])
plt.plot(G_PTS_2[0][:,0],G_PTS_2[0][:,1],'+r')
plt.show()

# normalise image arrays between 0-1 and center points between -0.5-0.5
N_TRAIN = G_TRAIN_2/255.0
N_PTS = G_PTS_2/76-0.5

plt.imshow(N_TRAIN[1])
plt.plot((N_PTS[1][:,0]+0.5)*76,(N_PTS[1][:,1]+0.5)*76,'+r')
plt.show()

"""# Building the CNN"""

# Import the needed libraries for CNN
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.callbacks import ModelCheckpoint, History
from keras.optimizers import Adam
from keras.models import load_model

hist = History()

X_train = N_TRAIN.reshape(N_TRAIN.shape[0],76,76,1)
Y_train = N_PTS.reshape(N_PTS.shape[0],-1)

model = Sequential()
model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(76, 76, 1)))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))
model.add(MaxPooling2D(pool_size=2))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(136))
model.summary()
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])

# Train on original data
hist = model.fit(X_train, Y_train, validation_split=0.3, batch_size=64,shuffle=True, epochs=150, verbose=1)

# loss plot 
plt.figure(figsize=(16,5))
plt.subplot(1, 2, 1)
plt.suptitle('Original Data', fontsize=10)
plt.ylabel('Loss', fontsize=16)
plt.xlabel('Epochs', fontsize=16)
plt.plot(hist.history['loss'], color='r', label='Training Loss')
plt.plot(hist.history['val_loss'], color='b', label='Validation Loss')
plt.legend(loc='upper right')

# accuracy plot
plt.subplot(1, 2, 2)
plt.ylabel('Accuracy', fontsize=16)
plt.xlabel('Epochs', fontsize=16)
plt.plot(hist.history['accuracy'], color='r', label='Training Accuracy')
plt.plot(hist.history['val_accuracy'], color='b', label='Validation Accuracy')
plt.legend(loc='lower right')
plt.show()

# Load the test data using np.load
test_data = np.load('test_images.npz', allow_pickle=True)

# Extract the images
test_images = test_data['images']

test_imgs = np.copy(test_images)
test_imgs.shape

# Change the test data to be the same as the train data we trained on by turning it into grayscale, resizing, and normalising the points.
G_TEST = []
for i in range(0,test_imgs.shape[0]):
  G_TEST.append(cv2.cvtColor(test_imgs[i],cv2.COLOR_BGR2GRAY))
G_TEST = np.array(G_TEST)
G_TEST.shape

G_TEST_2 = []
for i in range(0,G_TEST.shape[0]):
  G_TEST_2.append(cv2.resize(G_TEST[i],(76,76)))
G_TEST_2 = np.array(G_TEST_2)
G_TEST_2.shape

N_TEST = G_TEST_2/255.0

# Predict
points_test = model.predict(N_TEST.reshape(N_TEST.shape[0], 76, 76, 1))

# Reshape for plotting
test_pts = points_test.reshape(points_test.shape[0],68,-1)

# Examples of the plotting. Change the index '7' for different images
plt.imshow(N_TEST[7])
plt.plot((test_pts[7][:,0]+0.5)*76,(test_pts[7][:,1]+0.5)*76,'+r')
plt.show()

# Augmenting by flipping the training images and points
def augment_data(img, points):
    rows, cols = img.shape
    new_img = np.copy(img)
    
    # flip the image
    for i in range(76):
        for j in range(38):
            temp = img[i][j]
            new_img[i][j] = img[i][cols-j-1]
            new_img[i][cols-j-1] = temp
            
    # flip the points
    new_points = np.copy(points)
    for i in range(0,68):
        new_points[i,::2] = -points[i,::2]
        
    return new_img, new_points

# Make an np array F_TRAIN which contains all the flipped images, F_PTS which has all the flipped points
# create an empty list first
F_TRAIN = []
F_PTS = []
# Iterate through the normalised images
for i in range(0,N_TRAIN.shape[0]):
  # call the flipping function
  f_img,f_pts = augment_data(N_TRAIN[i],N_PTS[i])

  # append flipped data into the lists
  F_TRAIN.append(f_img)
  F_PTS.append(f_pts)

# turn them into np arrays
F_TRAIN = np.array(F_TRAIN)
F_PTS = np.array(F_PTS)

# Add some gaussian blur to images
def augment_data2(img,pts,k=11,k2=11,sigma=1.0):
  smooth_img = cv2.GaussianBlur(img, (k,k2), sigma)
  return smooth_img,pts

aug_data = []
aug_pts = []

for i in range(0,F_TRAIN.shape[0]):
  # add gaussian blur to flipped data
  f_img2,f_pts2 = augment_data2(F_TRAIN[i],F_PTS[i])
  
  # Append into the lists
  aug_data.append(f_img2)
  aug_pts.append(f_pts2)

# Turn lists into np arrays
aug_data = np.array(aug_data)
aug_pts = np.array(aug_pts)

plt.imshow(aug_data[1])
plt.plot((aug_pts[1][:,0]+0.5)*76,(aug_pts[1][:,1]+0.5)*76,'+r')
plt.show()

# convolve augmentation
# calculates the horizontal gradient of images using some simple finite kernel [-1, 0, 1]
from scipy.signal import convolve2d
def augment_data3(img,pts):
  # first add the gaussian blur to smooth the images
  img2,pts2 = augment_data2(img,pts)
  # then convolve
  horz_grad = convolve2d(img2, [[-1, 0, 1]], mode='same')
  return horz_grad,pts2

# Now we make the final augmented array (resized, flipped, smoothed out with Gaussian blur, and convolved)
# First create empty lists
aug_data2 = []
aug_pts2 = []

# Iterate through the flipped images
for i in range(0,F_TRAIN.shape[0]):
  # Call the function
  f_img3,f_pts3 = augment_data3(F_TRAIN[i],F_PTS[i])
  
  # Append into the lists
  aug_data2.append(f_img3)
  aug_pts2.append(f_pts3)

# Turn into np arrays
aug_data2 = np.array(aug_data2)
aug_pts2 = np.array(aug_pts2)

# Just a visualisation of the final product
plt.imshow(aug_data2[1])
plt.plot((aug_pts2[1][:,0]+0.5)*76,(aug_pts2[1][:,1]+0.5)*76,'+r')
plt.show()

# We must reshape the augmented images into the acceptable format by Tensorflow (num of imgs,w,h,1)
x2_train = aug_data2.reshape(aug_data2.shape[0],76,76,1) # (2811,76,76,1)
# Because our final Dense layer has an output of 138, we must reshape the training points to be the same.
y2_train = aug_pts2.reshape(aug_pts2.shape[0],-1) # (2811,138)

# Shuffle the data altogether. This is another augmentation technique
from sklearn.utils import shuffle
x3_train,y3_train = shuffle(x2_train,y2_train)

# Build the final model
model4 = Sequential()
model4.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(76, 76, 1)))
model4.add(MaxPooling2D(pool_size=2))

model4.add(Conv2D(filters=32, kernel_size=3, activation='relu'))
model4.add(MaxPooling2D(pool_size=2))

model4.add(Conv2D(filters=64, kernel_size=3, activation='relu'))
model4.add(MaxPooling2D(pool_size=2))

model4.add(Conv2D(filters=128, kernel_size=3, activation='relu'))
model4.add(MaxPooling2D(pool_size=2))

model4.add(Flatten())
model4.add(Dense(1024, activation='relu'))
model4.add(Dropout(0.2))
model4.add(Dense(1024, activation='relu'))
model4.add(Dropout(0.2))

model4.add(Dense(136))
model4.summary()
model4.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001), metrics=['accuracy'])

hist4 = model4.fit(x3_train, y3_train, validation_split=0.3, batch_size=64,shuffle=True, epochs=50, verbose=1)

# loss plot 
plt.figure(figsize=(16,5))
plt.subplot(1, 2, 1)
plt.suptitle('Augmented Data', fontsize=10)
plt.ylabel('Loss', fontsize=16)
plt.xlabel('Epochs', fontsize=16)
plt.plot(hist4.history['loss'], color='r', label='Training Loss')
plt.plot(hist4.history['val_loss'], color='b', label='Validation Loss')
plt.legend(loc='upper right')

# accuracy plot
plt.subplot(1, 2, 2)
plt.ylabel('Accuracy', fontsize=16)
plt.xlabel('Epochs', fontsize=16)
plt.plot(hist4.history['accuracy'], color='r', label='Training Accuracy')
plt.plot(hist4.history['val_accuracy'], color='b', label='Validation Accuracy')
plt.legend(loc='lower right')
plt.show()

# loss plot 
plt.figure(figsize=(16,5))
plt.subplot(1, 2, 1)
plt.suptitle('Augmented Data: 2nd training', fontsize=10)
plt.ylabel('Loss', fontsize=16)
plt.xlabel('Epochs', fontsize=16)
plt.plot(hist4.history['loss'], color='r', label='Training Loss')
plt.plot(hist4.history['val_loss'], color='b', label='Validation Loss')
plt.legend(loc='upper right')

# accuracy plot
plt.subplot(1, 2, 2)
plt.ylabel('Accuracy', fontsize=16)
plt.xlabel('Epochs', fontsize=16)
plt.plot(hist4.history['accuracy'], color='r', label='Training Accuracy')
plt.plot(hist4.history['val_accuracy'], color='b', label='Validation Accuracy')
plt.legend(loc='lower right')
plt.show()

# loss plot 
plt.figure(figsize=(16,5))
plt.subplot(1, 2, 1)
plt.suptitle('Augmented Data: 3rd training', fontsize=10)
plt.ylabel('Loss', fontsize=16)
plt.xlabel('Epochs', fontsize=16)
plt.plot(hist4.history['loss'], color='r', label='Training Loss')
plt.plot(hist4.history['val_loss'], color='b', label='Validation Loss')
plt.legend(loc='upper right')

# accuracy plot
plt.subplot(1, 2, 2)
plt.ylabel('Accuracy', fontsize=16)
plt.xlabel('Epochs', fontsize=16)
plt.plot(hist4.history['accuracy'], color='r', label='Training Accuracy')
plt.plot(hist4.history['val_accuracy'], color='b', label='Validation Accuracy')
plt.legend(loc='lower right')
plt.show()



# Now, apply the same augmentation to the normalised test set.
x_test2 = []

# Iterate through test images
for i in range(0,N_TEST.shape[0]):
  # convolve, the f_pts3 is unnecessary but the augment_data3 function needs a second parameter.
  test_,f_pts3 = augment_data3(N_TEST[i],F_PTS[i])
  
  # Append the augmented test images into the list
  x_test2.append(test_)
  

# Turn list into an np array
x_test2 = np.array(x_test2)
x_test2.shape

# Predict the points for the augmented test set. Make sure to reshape it into the acceptable format by Tensorflow
predicted_points = model4.predict(x_test2.reshape(x_test2.shape[0], 76, 76, 1))

# Now reshape the coordinates because they are all stacked together. We want an array shape of (num of test,68,2) for the (x,y) coordinates
test_points_2 = predicted_points.reshape(predicted_points.shape[0],68,-1)

save_as_csv(test_points_2)



# Plot the test images. Test it by changing the index '50' or use the function visualise pts. Personally it was crashing my computer at times.
plt.imshow(N_TEST[70])
plt.plot((test_points_2[70][:,0]+0.5)*76,(test_points_2[70][:,1]+0.5)*76,'+r')
plt.show()

# For Calculating the euclid_dist
prd_train = model4.predict(x2_train)

prd_train = prd_train.reshape(prd_train.shape[0],68,-1)

plt.imshow(F_TRAIN[10])
plt.plot((prd_train[10][:,0]+0.5)*76,(prd_train[10][:,1]+0.5)*76,'+r')
plt.show()

plt.imshow(F_TRAIN[10])
plt.plot((F_PTS[10][:,0]+0.5)*76,(F_PTS[10][:,1]+0.5)*76,'+r')
plt.show()

# Calculate the euclid distance
euclid_dist((prd_train[10]+0.5)*76,(N_PTS[10]+0.5)*76)

# Another example
plt.imshow(F_TRAIN[5])
plt.plot((prd_train[5][:,0]+0.5)*76,(prd_train[5][:,1]+0.5)*76,'+r')
plt.show()

# Original
plt.imshow(F_TRAIN[5])
plt.plot((F_PTS[5][:,0]+0.5)*76,(F_PTS[5][:,1]+0.5)*76,'+r')
plt.show()

euclid_dist((prd_train[5]+0.5)*76,(N_PTS[5]+0.5)*76)

# # This is another augmentation technique which adds random noise to the images. However, my computer couldn't load it. 
# noise_x = []
# for i in range(0,F_TRAIN.shape[0]):
#   # add random noise
#   noisy_xTrain = F_TRAIN[i] + np.random.randn(*F_TRAIN.shape) * 10.0
#   # clip array to be between 0-1 because it's a normalised image
#   noisy_xTrain = np.uint8(np.clip(noisy_xTrain, 0, 1))
#   noise_x.append(noisy_xTrain)

# NOISE_xTrain = np.array(noise_x)

# plt.imshow(NOISE_xTrain[5])
# plt.plot((F_PTS[5][:,0]+0.5)*76,(F_PTS[5][:,1]+0.5)*76,'+r')
# plt.show()

"""# Skin Segmentation"""

# Load the data using np.load
examples_data = np.load('examples.npz', allow_pickle=True)

# Extract the images
e_images = examples_data['images']

e_images.shape

# Visualising images
plt.imshow(e_images[1])
plt.show()

# Start image preprocessing: turn into grayscale, rescale into 76x76, normalise, etc

# Turn into grayscale
E_IMGS = []
for i in range(0,e_images.shape[0]):
  E_IMGS.append(cv2.cvtColor(e_images[i],cv2.COLOR_BGR2GRAY))
E_IMGS = np.array(E_IMGS)
E_IMGS.shape

# Rescale images into 76x76
E_IMGS2 = []
for i in range(0,E_IMGS.shape[0]):
  E_IMGS2.append(cv2.resize(E_IMGS[i],(76,76)))
E_IMGS2 = np.array(E_IMGS2)
E_IMGS2.shape

plt.imshow(E_IMGS2[1])
plt.show()

# Normalise
E_IMGS3 = E_IMGS2/255.0

# Flip images

E_imgs_flipped = []
# Iterate through the normalised images
for i in range(0,E_IMGS3.shape[0]):
  # call the flipping function, f_pts is irrelevant 
  e_img,f_pts = augment_data(E_IMGS3[i],N_PTS[i])

  # append flipped data into the lists
  E_imgs_flipped.append(e_img)
  

# turn them into np arrays
E_imgs_flipped = np.array(E_imgs_flipped)

# Gaussian blur & convolve

E_imgs_aug = []

# Iterate through test images
for i in range(0,E_imgs_flipped.shape[0]):
  # convolve, the f_pts3 is unnecessary but the augment_data3 function needs a second parameter.
  examples_,f_pts3 = augment_data3(E_imgs_flipped[i],F_PTS[i])
  
  # Append the augmented test images into the list
  E_imgs_aug.append(examples_)
  

# Turn list into an np array
E_imgs_aug = np.array(E_imgs_aug)

plt.imshow(E_imgs_aug[1])

E_predictions = model4.predict(E_imgs_aug.reshape(E_imgs_aug.shape[0],76,76,1))

E_predictions2 = E_predictions.reshape(E_predictions.shape[0],68,2)

plt.imshow(E_imgs_flipped[5])
plt.plot((E_predictions2[5][:,0]+0.5)*76,(E_predictions2[5][:,1]+0.5)*76,'+r')
plt.show()

# Now for the graphical effects
def face_seg(img,pts,color1=255,color2=255,color3=255,line=4,shift=0):
# Create a zeros numpy array of the image 
  curr = np.zeros((76,76),dtype = np.uint8)
  # the landmarks
  regions = pts

  fig, (ax1, ax2) = plt.subplots(1, 2)
  fig.suptitle('Face segmentation before and after')

  # do  segmentation and plot it
  cv2.fillPoly(curr, np.int32([regions]), [color1,color2,color3],lineType=line,shift=shift)
  ax2.imshow(curr)
  ax1.imshow(img)

face_seg(e_images[2],(E_predictions2[2]+0.5)*76,color1=233,color2=231,color3=1)

"""# Graphical Effects

For graphical effects, I will be adding a n95 mask
"""

















